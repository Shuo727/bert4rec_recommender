{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e125714",
   "metadata": {},
   "source": [
    "# Construct Training/Test Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5d21cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[303, 586, 785, 818, 1174, 1195, 80, 601, 1145, 1244, 2178, 36, 110, 1231, 1654, 1937, 17, 30, 1093, 1123, 1183, 1191, 1215, 1656, 1873, 2222, 25, 888, 903, 1155, 1263, 2430, 1019, 1323, 1369, 1631, 304, 1033, 1198, 2223, 299, 636, 951, 1728, 1864, 2239, 2621, 906, 1357, 1932], [293, 376, 152, 340, 345, 581, 229, 315, 588, 335, 184, 251, 453, 34, 223, 39, 360, 450, 352, 234, 280, 185, 373, 346, 496, 353, 535, 580, 48, 579, 590, 31, 192, 274, 546, 235, 578, 504, 217, 377, 220, 547, 206, 215, 302, 462, 587, 516, 609, 358]]\n",
      "[[586, 785, 818, 1174, 1195, 80, 601, 1145, 1244, 2178, 36, 110, 1231, 1654, 1937, 17, 30, 1093, 1123, 1183, 1191, 1215, 1656, 1873, 2222, 25, 888, 903, 1155, 1263, 2430, 1019, 1323, 1369, 1631, 304, 1033, 1198, 2223, 299, 636, 951, 1728, 1864, 2239, 2621, 906, 1357, 1932, 2036], [376, 152, 340, 345, 581, 229, 315, 588, 335, 184, 251, 453, 34, 223, 39, 360, 450, 352, 234, 280, 185, 373, 346, 496, 353, 535, 580, 48, 579, 590, 31, 192, 274, 546, 235, 578, 504, 217, 377, 220, 547, 206, 215, 302, 462, 587, 516, 609, 358, 768]]\n",
      "{'users_total': 200948, 'users_kept': 200948, 'num_items': 84432, 'avg_train_len': 42.99, 'avg_test_len': 43.36, 'max_len': 50, 'min_user_interactions': 5}\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))  # add project root\n",
    "\n",
    "from src.data_loader import prepare_movielens_sequences\n",
    "from src.datasets import SequenceDataset, collate_fn\n",
    "\n",
    "MAX_LEN = 50\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Call the function to load and preprocess the MovieLens data\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'data/raw'))\n",
    "csv_path = os.path.join(data_dir, 'ml_32m_ratings.csv')\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
    "\n",
    "bundle = prepare_movielens_sequences(\n",
    "    ratings_path=csv_path,\n",
    "    max_len=50,\n",
    "    min_user_interactions=5,\n",
    ")\n",
    "\n",
    "train_sequences = bundle[\"train_sequences\"]\n",
    "test_sequences = bundle[\"test_sequences\"]\n",
    "num_items = bundle[\"num_items\"]\n",
    "mask_id = bundle[\"mask_id\"]\n",
    "pad_id = bundle[\"pad_id\"]\n",
    "\n",
    "# Preview the processed data\n",
    "print(train_sequences[:2])\n",
    "print(test_sequences[:2])\n",
    "print(bundle[\"stats\"])\n",
    "\n",
    "# Build loaders\n",
    "from torch.utils.data import DataLoader\n",
    "train_ds = SequenceDataset(train_sequences, max_len=MAX_LEN)\n",
    "test_ds  = SequenceDataset(test_sequences,  max_len=MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e311122e",
   "metadata": {},
   "source": [
    "# Train BERT4Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd52eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  34%|███▍      | 268/785 [30:44<57:43,  6.70s/it]  "
     ]
    }
   ],
   "source": [
    "from src.model import BERT4Rec\n",
    "from src.trainer import train_one_epoch, evaluate_mlm_loss\n",
    "import torch\n",
    "\n",
    "MLM_PROB = 0.15\n",
    "\n",
    "# Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERT4Rec(num_items=num_items, pad_id=pad_id, mask_id=mask_id, max_len=MAX_LEN).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
    "\n",
    "# Train a few epochs\n",
    "num_epoch = 3\n",
    "for ep in range(num_epoch):\n",
    "    tr = train_one_epoch(model, train_loader, opt, device, mlm_prob=MLM_PROB)\n",
    "    ev = evaluate_mlm_loss(model, test_loader, device, mlm_prob=MLM_PROB)\n",
    "    print(f\"epoch {ep} | train_loss {tr['loss']:.4f} | eval_loss {ev['loss']:.4f}\")\n",
    "\n",
    "CKPT_PATH = os.path.abspath(os.path.join(os.getcwd(), '..', 'model/bert4rec_checkpoint.pth'))\n",
    "torch.save({\n",
    "    \"epoch\": num_epoch,\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": opt.state_dict(),\n",
    "    \"loss\": tr,\n",
    "}, CKPT_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
